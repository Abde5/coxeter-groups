%%%%%%%%%%%%%%%%%%%% book.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for the chapters of your "monograph"
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%


% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[envcountsame,envcountchap]{svmono}
%\documentclass[envcountsame,envcountchap]{svmono}

% choose options for [] as required from the list
% in the Reference Guide, Sect. 2.2

\usepackage{makeidx}         % allows index generation
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{amsmath,amssymb}         % matrices
\usepackage{enumerate}
                             % when including figure files
\usepackage{multicol}        % used for the two-column index
\usepackage[bottom]{footmisc}% places footnotes at page bottom
% etc.
% see the list of further useful packages
% in the Reference Guide, Sects. 2.3, 3.1-3.3


\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\support}{supp}


% NEW COMMANDS

%It is standard in Latex to write "macros" which are shorthand for an entire series of instructions. Here are some examples

%Number sets
\newcommand{\N}{\mathbb N}
%So typing \N produces the correct mathematical symbol for the natural numbers
\newcommand{\Z}{\mathbb Z}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\K}{\mathbb K}
%notations quelquonques
\newcommand{\tg}[1]{\textbf{#1}}
\newcommand{\ub}[1]{\overline{#1}}

%notations des objets simples
\newcommand{\es}{\emptyset}
\newcommand{\nes}{$\not= \emptyset$}
\newcommand{\sub}{\subset}
\newcommand{\norm}[2]{\lVert #1 \lVert_{#2}}
\newcommand{\vect}[2]{(#1_1,#1_2, \dots, #1_#2)}
\newcommand{\modu}[1]{\lvert#1\lvert}
\newcommand{\B}[3]{B_{#1}\big(#2,#3\big[}
%notations math√©matiques
\newcommand{\lb}{\lbrack}
\newcommand{\rb}{\rbrack}
\newcommand{\lv}{\lVert}
%limits and sum
\newcommand{\s}[2]{\sum\limits_{#1}^{#2}}
\newcommand{\li}[2]{\xrightarrow[#1\rightarrow#2]{}}
\newcommand{\lis}[1]{\xrightarrow[n\rightarrow+\infty]{#1}}
\newcommand{\lif}[1]{\xrightharpoonup[n\rightarrow+\infty]{#1}}
\newcommand{\lic}[3]{\xrightarrow[#1\rightarrow#2]{#3}}

\newcommand{\bcup}[2]{\bigcup\limits_{#1}^{#2}}
\newcommand{\bcap}[2]{\bigcap\limits_{#1}^{#2}}

\newcommand{\inv}[1]{\frac{1}{#1}}
\newcommand{\prods}[2]{\langle\qq #1\qq,\qq#2\qq\rangle}

\newcommand{\restr}[2]{#1_{\mkern 2mu \vrule height 2ex\mkern2mu #2} }
\newcommand{\quot}[2]{{\raisebox{.2em}{$#1$}\left/\raisebox{-.2em}{$#2$}\right.}}
\newcommand{\limite}[2]{\underset{#1\rightarrow#2}{\text{lim}}}
\newcommand{\espp}[2]{Ker\big(u-{#1} Id_{#2}\big)}
\newcommand{\fct}[4]{\qq:\qq #1\qq\longrightarrow\qq #2\qq :\qq #3\qq \mapsto\qq #4}

\newcommand{\lam}{\lambda}
\newcommand{\q}{\quad}
\newcommand{\qq}{\text{ }}

\newcommand{\liste}[2]{#1_1, #1_2,..,#1_{#2}}

\newcommand{\maxx}[1]{\underset{#1}{\text{max}}}
\newcommand{\minn}[1]{\underset{#1}{\text{min}}}
\newcommand{\supp}[1]{\underset{#1}{\text{sup}}}
\newcommand{\inff}[1]{\underset{#1}{\text{inf}}}

\newcommand{\fctt}[2]{\qq:\qq#1\qq\rightarrow\qq#2}
\newcommand{\liminff}[1]{\underset{#1\rightarrow+\infty}{\text{liminf}}}
\newcommand{\limsupp}[1]{\underset{#1\rightarrow+\infty}{\text{limsup}}}

\newcommand{\adh}[2]{\text{Adh}_{#1}\big(#2\big)}
\newcommand{\wed}[3]{#1_#2\wedge\dots \wedge #1_#3}


\makeindex             % used for the subject index
                       % please use the style svind.ist with
                       % your makeindex program


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\author{MATH-F-427 students}
\title{Coxeter groups}
\subtitle{Course notes}
\maketitle

\frontmatter%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents


\mainmatter%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Warnig: hypothesis reduced in the exchange property!}


\begin{theorem} [Matsumoto]
Let $W$ be a group and $S \subset W$ a finite subset of generators of $W$ of order $2$. Then the following assertions are equivalent:
\begin{itemize}
\item $(i)$ $(W, S)$ is a Coxeter system. 
\item $(ii)$ $(W, S)$ satisfies the exchange property.
\item $(iii)$ $(W,S)$ satisfies the deletion property.
\end{itemize}  
\end{theorem}	
\begin{proof}
$(i) \Rightarrow (ii)$. This implication has already been shown above. 

$(ii) \Rightarrow (iii)$. Let $w= s_1 \ldots s_k$ such that $\ell(w) < k$. Let $i$ be maximal such that $s_i s_{i+1} \ldots s_k$ is not reduced (i.e. $s_{i+1} \ldots s_k$ is reduced). We have $\ell (s_i s_{i+1} \ldots s_k) \le k- i = \ell (s_{i+1} \ldots s_k)$. Now, using exchange property, we obtain $s_i s_{i+1} \ldots s_k = s_{i+1} \ldots \hat{s}_j \ldots s_k$ for some $i+1 \le j \le k$. Therefore, $w = s_1 \ldots s_{i-1} s_i s_{i+1} \ldots s_k = s_1 \ldots s_{i-1} \hat{s}_i s_{i+1} \ldots \hat{s}_j \ldots s_k$ and we have the result (let us note that this implication remains true for weaker hypothesis since we did not use the fact that $S$ is of order $2$).  

$(iii) \Rightarrow (ii)$. Let $w= s_1 \ldots s_k$, $k = \ell (w)$, $s\in S$, such that $\ell (s w) = \ell (s s_1 \ldots s_k) \le \ell (w) = \ell (s_1 \ldots s_k ) = k$. So $s s_1 \ldots s_k$ is not reduced. We can apply the deletion property. Suppose that $s w = s s_1 \ldots \hat{s}_i \ldots \hat{s}_j \ldots s_k $ (but $\ell (sw) \le k-1 < l(w)$). So $s s w = s s s_i \ldots \hat{s}_i \ldots {\hat{s}_j} \ldots s_k$. This leads to $\ell (s_1 \ldots ... \hat{s}_i \ldots \hat{s}_j \ldots s_k ) < k$, which is a contradiction, so this case has to be excluded. Hence, we have $s w = \hat{s} s_1 \ldots \hat{s}_i  \ldots s_k $. 

$(ii) \Rightarrow (i)$. Using $(ii) \Rightarrow (iii)$, we can assume both $(ii)$ and $(iii)$. Define $m(s,s') = \text{order of $ss'$ in $W$, for all $s,s' \in S$}$. Let $(\tilde{W}, S)$ be the Coxeter group associated to $m$. Clearly, $\phi: \tilde{W} \mapsto W, s \to s$ is a surjective homomorphism. We need to show that $\phi$ is also injective. Let $s_1 \ldots s_m = e$ in $W$. By the deletion property, $m$ is even, say $m=2k$. So we can write our relation on the form
\begin{equation}
s_1 \ldots s_k = s'_1 \ldots s_k'
\label{relation}
\end{equation} where $s_1' = s_{2k}$, $\ldots$ $s_k' = s_{k+1}$. We must now prove that \eqref{relation} is a consequence of the pairwise relations $(ss')^{m(s,s')} = e$. The proof is done by induction on $k$, the case $k = 1$ being trivially correct. 
\begin{itemize}
\item \underline{Case 1:} Suppose $w := s_1 \ldots s_k$ is not reduced. By deletion property, there exists a position $1 \le i <k$ such that $s_{i+1} s_{i+2} \ldots s_k$ is reduced but $s_i s_{i+1} s_{i+2} ...s_k$ is not. By the exchange property, we then have that $s_{i+1} s_{i+2} \ldots s_k = s_i s_{i+1} \ldots \hat{s}_j \ldots s_k$ for some $i < j \le k$. This relation is of length $<2k$ and hence fine. Plugging this result into \eqref{relation} gives $s_1 \ldots s_i s_i s_{i+1} \ldots \hat{s}_j \ldots s_k = s_1' s_2' \ldots s'_k$. The factor $s_i s_i$ can be deleted, leaving a relation of length $<2k$. Hence the relation \eqref{relation} is fine. 
\item \underline{Case 2:} Suppose $w = s_1 \ldots s_k$ is reduced, $k = \ell (w)$. We can assume that $s_1 \neq s_1'$ (otherwise the relation \eqref{relation} is equivalent to a shorter relation). We have $\ell (s_1' s_1 s_2 \ldots s_k) = \ell (s_1' s_1' s_2' \ldots s_k') = \ell( s_2' \ldots s_k')  \le k-1 < \ell (s_1 \ldots s_k)$. Using exchange property, we have $s_1' s_1 \ldots s_k = s_1 \ldots \hat{s}_i \ldots s_k$ for some $i$. Hence, $s_1 \ldots \hat{s}_i \ldots s_k = s_2' \ldots s'_k$. 

If $i<k$, then $s_1' s_1 s_2 \ldots s_{k-1} = s_1 \ldots \hat{s}_i \ldots s_{k-1}$. So $s_1' s_1 s_2 \ldots s_{k-1} s_k = s_1 \ldots \hat{s}_i \ldots s_{k-1} s_k$. Hence, $s_1' s_1 \ldots s_k = s_2' \ldots s_k$ is a consequence of Coxeter relations.  

If $i=k$, we have to work a little bit harder. We have $s_1' s_1 \ldots s_{k-1} = s_1' s_2' \ldots s_k' $. Thus it will suffice to show that $s_1 s_1 \ldots s_{k-1} = s_1 s_2 \ldots s_k$ is a consequence of Coxeter relations. Applying recursively the rule, we have $s_1 s_1' s_1 \ldots s_{k-2} = s'_1 s_1 \ldots s_{k-1}$ $\Rightarrow$ $s_1' s_1 s'_1 s_1 \ldots s_{k-3} = s_1 s_1' s_1 \ldots s_{k-2}$ $\Rightarrow$ $\ldots$ Thus in the end, the question will be reduced to the relation $s_1 s_1' s_1 s_1' \ldots = s_1' s_1 s_1' s_1 \ldots$, which is of course a consequence of the Coxeter relation $(s_1 s_1')^{m(s,s')}= e$. 


\end{itemize}

\end{proof}


\begin{example}
The group $S_n$ can be generated by transpositions, which are order $2$ elements. Using the above theorem, we conclude that $S_n$ is actually a Coxeter group. 
\end{example}

\section{Geometric representation}

Let $(W, S)$ be a Coxeter system, $S = \{s_1, \ldots s_n \}$, $m$ the associated Coxeter matrix. We write $m_{ij} = m(s_i, s_j)$. Let $V$ be a $\mathbb{R}$-vector space of dimension $n$, with a basis $\alpha_1, \ldots , \alpha_n$. We consider the symmetric bilinear map
\begin{equation}
\langle \cdot, \cdot \rangle : V \times V \mapsto \mathbb{R}
\end{equation} defined through
\begin{equation}
\langle \alpha_i , \alpha_j \rangle = \left \{
\begin{array}{c @{} c}
    &- \cos \left(\frac{\pi}{m_{ij}} \right) \quad \text{if } m_{ij} < + \infty \\
    &-1 \quad ~~~~~~~~~~~~~\text{if } m_{ij} = + \infty \\
\end{array}
\right.
\end{equation} Not that $\langle \cdot, \cdot \rangle$ is not positive definite in general. 

\begin{proposition}
The following map extends to a homomorphism:
\begin{equation}
W \mapsto GL(V), s_i \to \sigma_i
\end{equation} where $\sigma_i :v \to  v - 2 \langle v, \alpha_i \rangle \alpha_i$. 
\end{proposition}

\begin{remark}
We have $\sigma_i (\alpha_i) = \alpha_i - 2 \langle \alpha_i, \alpha_i \rangle \alpha_i = - \alpha_i$. Thus, if $v\in V$ is such that $\langle v, \alpha_i \rangle = 0$, then $\sigma_i (v) = v$. Therefore, if $\langle \cdot, \cdot \rangle$ was positive definite, $\sigma_i$ would be interpreted as a reflexion through the hyperplane orthogonal to $\alpha_i$. 
\end{remark}

\begin{proof}
First, let us show that $\sigma_i$ is invertible for all $i$. We have $\sigma^2_i (v) = \sigma_i (v) - 2 \langle v, \alpha_i \rangle \sigma_i (\alpha_i) = v - 2  \langle v, \alpha_i \rangle \alpha_i + 2  \langle v, \alpha_i \rangle \alpha_i = v$. 

Now, let us show that $(\sigma_i \sigma_j)^{m_{ij}} = Id_V$. For $i\neq j$, define $V_{ij} = \text{Span}_\mathbb{R} ( \{ \alpha_i , \alpha_j \} )$. Furthermore, $V_{ij}^\perp = \{ v\in V | \langle v, \alpha_i \rangle = 0, \langle v, \alpha_j \rangle = 0 \}$. Before proceeding, we show the following lemma:

\begin{lemma}
$V = V_{ij} \oplus V_{ij}^\perp$ if $m_{ij} < + \infty$. 
\end{lemma}
 
\begin{proof}
Let $v \in V$. We want to find $\lambda_i, \lambda_j \in \mathbb{R}$ such that $\tilde{v} = \lambda_i \alpha_i + \lambda_j \alpha_j \in V_{ij}$ and $v - \tilde{v} \in V_{ij}^\perp$. We have
\begin{equation}
\begin{split}
\langle \tilde{v}, \alpha_i \rangle &= \lambda_i \langle \alpha_i , \alpha_i \rangle + \lambda_j \langle \alpha_i, \alpha_j \rangle \\
&= \lambda_i + C \lambda_j
\end{split}
\end{equation} where $C = \langle \alpha_i, \alpha_j \rangle = - \cos \left( \frac{\pi}{m_{ij}} \right)$. Furthermore,
\begin{equation}
\langle \tilde{v}, \alpha_j \rangle = \lambda_i C + \lambda_j
\end{equation} Since 
\begin{equation}
\det \begin{pmatrix}
1 & C \\
C & 1 
\end{pmatrix} = 1 - C^2 = 1 - \cos^2 \left( \frac{\pi}{m_{ij}} \right) \neq 0, 
\end{equation} if $m_{ij} < + \infty$. Therefore, we can find unique $\lambda_i$ and $\lambda_j$ such that
\begin{equation}
\langle \tilde{v} , \alpha_i \rangle = \langle v, \alpha_i \rangle \quad \text{and} \quad \langle \tilde{v} , \alpha_j \rangle = \langle v, \alpha_j \rangle  
\end{equation} 
\end{proof} 

Now let us come back to the proof of the proposition. Using the lemma, we have $v = \tilde{v} + (v- \tilde{v})$ such that $\langle v - \tilde{v} , \alpha_i \rangle = 0 = \langle v - \tilde{v}, \alpha_j \rangle = 0$. Hence $\sigma_i (v - \tilde{v}) = v- \tilde{v} - 2 \langle v - \tilde{v} , \alpha_i \rangle \alpha_i = v- \tilde{v}$ and $\sigma_j (v-\tilde{v}) = v - \tilde{v}$. In the basis $\{ \alpha_i, \alpha_j \}$ of $V_{ij}$, the matrix associated to $\sigma_i$ is given by
\begin{equation}
\begin{pmatrix}
-1 &-2 C \\
0 & 1
\end{pmatrix}
\end{equation} In fact, we have $\sigma_i (\alpha_i) = -\alpha_i$ and $\sigma_j (\alpha_j ) = \alpha_j - 2 C \alpha_i$. Similarly, the matrix associated to $\sigma_j$ is given by
\begin{equation}
\begin{pmatrix}
1 & 0 \\
-2C & -1
\end{pmatrix}
\end{equation} Therefore,
\begin{equation}
(\sigma_i) (\sigma_j) = \begin{pmatrix}
-1 &-2 C \\
0 & 1
\end{pmatrix} \begin{pmatrix}
1 & 0 \\
-2C & -1
\end{pmatrix} = \begin{pmatrix}
-1 + 4 C^2 & 2C \\
-2 C & -1
\end{pmatrix}
\end{equation} The characteristic polynomial $P$ of this matrix is given by $P(t) = t^2 - (-2 + 4 C^2 ) t + 1$.The roots are given by $t_\pm = \cos \left(\frac{2 \pi}{m_{ij}} \right) \pm i \sin \left( \frac{2 \pi}{m_{ij}} \right)$. This characterizes a rotation of $2 \pi / m_{ij}$. So, the order of $\sigma_i \sigma_j$ is given by $m_{ij}$. 


 
 
\end{proof}
  
	
\end{document}	